{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load library\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#task\\n'It was the best of times',\\n'it was the worst of times',\\n'it was the age of wisdom',\\n'it was the age of foolishness'\\n\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create text\n",
    "text_data = np.array(['I love Brazil. Brazil!',\n",
    "                      'Sweden is best',\n",
    "                      'Germany beats both'])\n",
    "'''\n",
    "#task\n",
    "'It was the best of times',\n",
    "'it was the worst of times',\n",
    "'it was the age of wisdom',\n",
    "'it was the age of foolishness'\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Bag Of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 2, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 1, 0, 1],\n",
       "       [1, 0, 1, 0, 1, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the bag of words feature matrix\n",
    "count = CountVectorizer()\n",
    "bag_of_words = count.fit_transform(text_data)\n",
    "\n",
    "# Show feature matrix\n",
    "bag_of_words.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Bag Of Words Matrix Column Headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beats', 'best', 'both', 'brazil', 'germany', 'is', 'love', 'sweden']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get feature names\n",
    "feature_names = count.get_feature_names()\n",
    "\n",
    "# View feature names\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View As A Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beats</th>\n",
       "      <th>best</th>\n",
       "      <th>both</th>\n",
       "      <th>brazil</th>\n",
       "      <th>germany</th>\n",
       "      <th>is</th>\n",
       "      <th>love</th>\n",
       "      <th>sweden</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   beats  best  both  brazil  germany  is  love  sweden\n",
       "0      0     0     0       2        0   0     1       0\n",
       "1      0     1     0       0        0   1     0       1\n",
       "2      1     0     1       0        1   0     0       0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create data frame\n",
    "pd.DataFrame(bag_of_words.toarray(), columns=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to generate bag of word vectors in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Itâ€™s always good to understand how the libraries in frameworks work, and understand the methods behind them. The better you understand the concepts, the better use you can make of frameworks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>The input to our code will be multiple sentences and the output will be the vectors.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Input text:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Joe waited for the train',\n",
       " 'The train was late',\n",
       " 'Mary and Samantha took the bus',\n",
       " 'I looked for Mary and Samantha at the bus station',\n",
       " 'Mary and Samantha arrived at the bus station early but waited until noon for the bus']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\"Joe waited for the train\", \"The train was late\", \"Mary and Samantha took the bus\",\n",
    "\"I looked for Mary and Samantha at the bus station\",\n",
    "\"Mary and Samantha arrived at the bus station early but waited until noon for the bus\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTokenize each the sentences, example:\\nInput : \"John likes to watch movies. Mary likes movies too\"\\nOuput : \"John\",\"likes\",\"to\",\"watch\",\"movies\",\"Mary\",\"likes\",\"movies\",\"too\"\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import statments\n",
    "import numpy\n",
    "import re\n",
    "\n",
    "'''\n",
    "Tokenize each the sentences, example:\n",
    "Input : \"John likes to watch movies. Mary likes movies too\"\n",
    "Ouput : \"John\",\"likes\",\"to\",\"watch\",\"movies\",\"Mary\",\"likes\",\"movies\",\"too\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by removing stopwords from the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_extraction(sentence):\n",
    "    ignore = ['a', \"the\", \"is\"]\n",
    "    words = re.sub(\"[^\\w]\", \" \",  sentence).split()\n",
    "    cleaned_text = [w.lower() for w in words if w not in ignore]\n",
    "    return cleaned_text    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 2: Apply tokenization to all sentences</b><br>\n",
    "The method iterates all the sentences and adds the extracted word into an array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentences):\n",
    "    words = []\n",
    "    for sentence in sentences:\n",
    "        w = word_extraction(sentence)\n",
    "        words.extend(w)\n",
    "        \n",
    "    words = sorted(list(set(words)))\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsentences = [\"Joe waited for the train\", \"The train was late\", \"Mary and Samantha took the bus\",\\n\"I looked for Mary and Samantha at the bus station\",\\n\"Mary and Samantha arrived at the bus station early but waited until noon for the bus\"]\\n\\nprint(\"The output of this method will be:\")\\ntokenize(sentences)\\n\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "sentences = [\"Joe waited for the train\", \"The train was late\", \"Mary and Samantha took the bus\",\n",
    "\"I looked for Mary and Samantha at the bus station\",\n",
    "\"Mary and Samantha arrived at the bus station early but waited until noon for the bus\"]\n",
    "\n",
    "print(\"The output of this method will be:\")\n",
    "tokenize(sentences)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 3: Build vocabulary and generate vectors</b><br>\n",
    "Use the methods defined in steps 1 and 2 to create the document vocabulary and extract the words from the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bow(allsentences):    \n",
    "    vocab = tokenize(allsentences)\n",
    "    print(\"Word List for Document \\n{0} \\n\".format(vocab));\n",
    "\n",
    "    for sentence in allsentences:\n",
    "        words = word_extraction(sentence)\n",
    "        bag_vector = numpy.zeros(len(vocab))\n",
    "        for w in words:\n",
    "            for i,word in enumerate(vocab):\n",
    "                if word == w: \n",
    "                    bag_vector[i] += 1\n",
    "                    \n",
    "        print(\"{0} \\n{1}\\n\".format(sentence,numpy.array(bag_vector)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the defined input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "allsentences = [\"Joe waited for the train\", \"The train was late\", \"Mary and Samantha took the bus\", \n",
    "            \"I looked for Mary and Samantha at the bus station\", \n",
    "            \"Mary and Samantha arrived at the bus station early but waited until noon for the bus\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output vectors for each of the sentences are:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word List for Document \n",
      "['and', 'arrived', 'at', 'bus', 'but', 'early', 'for', 'i', 'joe', 'late', 'looked', 'mary', 'noon', 'samantha', 'station', 'the', 'took', 'train', 'until', 'waited', 'was'] \n",
      "\n",
      "Joe waited for the train \n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.]\n",
      "\n",
      "The train was late \n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1.]\n",
      "\n",
      "Mary and Samantha took the bus \n",
      "[1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0.]\n",
      "\n",
      "I looked for Mary and Samantha at the bus station \n",
      "[1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "Mary and Samantha arrived at the bus station early but waited until noon for the bus \n",
      "[1. 1. 1. 2. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generate_bow(allsentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our previous code can be replaced with:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1]\n",
      " [1 0 0 1 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0]\n",
      " [1 0 1 1 0 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0]\n",
      " [1 1 1 2 1 1 1 0 0 0 1 1 1 1 2 0 0 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(allsentences)\n",
    "\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
